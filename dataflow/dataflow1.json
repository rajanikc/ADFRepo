{
	"name": "dataflow1",
	"properties": {
		"type": "MappingDataFlow",
		"typeProperties": {
			"sources": [
				{
					"linkedService": {
						"referenceName": "AzureSqlDatabase1",
						"type": "LinkedServiceReference"
					},
					"name": "source1"
				}
			],
			"sinks": [
				{
					"linkedService": {
						"referenceName": "LinkdServBlobStrgInput",
						"type": "LinkedServiceReference"
					},
					"name": "sink1"
				}
			],
			"transformations": [],
			"scriptLines": [
				"parameters{",
				"     ParamSrcTableName as string ('STUDENT_LIST'),",
				"     ParamSrcSchemaName as string ('dbo'),",
				"     ParamTargetFileName as string ('STUDENT_LIST')",
				"}",
				"source(allowSchemaDrift: true,",
				"     validateSchema: false,",
				"     format: 'table',",
				"     store: 'sqlserver',",
				"     schemaName: ($ParamSrcSchemaName),",
				"     tableName: ($ParamSrcTableName),",
				"     isolationLevel: 'READ_UNCOMMITTED') ~> source1",
				"source1 sink(allowSchemaDrift: true,",
				"     validateSchema: false,",
				"     input(",
				"          {_col0_} as string,",
				"          {_col1_} as string,",
				"          {_col2_} as string,",
				"          {_col3_} as string,",
				"          {_col4_} as string",
				"     ),",
				"     format: 'delimited',",
				"     container: 'blogstorageoutput',",
				"     columnDelimiter: ',',",
				"     escapeChar: '\\\\',",
				"     quoteChar: '',",
				"     columnNamesAsHeader: true,",
				"     partitionFileNames:[(concat($ParamTargetFileName,'.txt'))],",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true,",
				"     partitionBy('hash', 1)) ~> sink1"
			]
		}
	}
}